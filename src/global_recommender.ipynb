{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000199</th>\n",
       "      <td>200948</td>\n",
       "      <td>79702</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1294412589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000200</th>\n",
       "      <td>200948</td>\n",
       "      <td>79796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1287216292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000201</th>\n",
       "      <td>200948</td>\n",
       "      <td>80350</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1294412671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000202</th>\n",
       "      <td>200948</td>\n",
       "      <td>80463</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1350423800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32000203</th>\n",
       "      <td>200948</td>\n",
       "      <td>87304</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1350423523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000204 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp\n",
       "0              1       17     4.0   944249077\n",
       "1              1       25     1.0   944250228\n",
       "2              1       29     2.0   943230976\n",
       "3              1       30     5.0   944249077\n",
       "4              1       32     5.0   943228858\n",
       "...          ...      ...     ...         ...\n",
       "32000199  200948    79702     4.5  1294412589\n",
       "32000200  200948    79796     1.0  1287216292\n",
       "32000201  200948    80350     0.5  1294412671\n",
       "32000202  200948    80463     3.5  1350423800\n",
       "32000203  200948    87304     4.5  1350423523\n",
       "\n",
       "[32000204 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function takes a user and returns a list of recommeded movies\n",
    "ml_ratings = pd.read_csv('../data/ml-32m/ratings.csv')\n",
    "ml_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the similiarity function (Min-hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3270, 0.140625), (140016, 0.078125)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used to read the correct file\n",
    "threshold = 0.4\n",
    "\n",
    "# read files\n",
    "df_minhash = pd.read_pickle('../data/df_min_hash.pkl')\n",
    "with open(f'../data/lsh_groups_{threshold}.pkl', 'rb') as f:\n",
    "    dict_lsh = pickle.load(f)\n",
    "\n",
    "\n",
    "# make dict to convert from index to movieId\n",
    "index_to_id = dict(zip(df_minhash.index, df_minhash.movieId))\n",
    "id_to_index = dict(zip(df_minhash.movieId, df_minhash.index)) # reverse dict\n",
    "\n",
    "def movie_recommendation_min_hash(movie_id, id_to_index=id_to_index, index_to_id=index_to_id, dict_lsh=dict_lsh, df_minhash=df_minhash):\n",
    "    \"\"\"\n",
    "    This function takes a movieId and returns a list of recommended movies\n",
    "    \"\"\"\n",
    "    index = id_to_index[movie_id]\n",
    "    similar_movies = []\n",
    "    for idx in dict_lsh[index]:\n",
    "        jaccard_score = df_minhash['minhash'][index].jaccard(df_minhash['minhash'][idx])\n",
    "        similar_movies.append((index_to_id[idx], jaccard_score))\n",
    "    \n",
    "    similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)\n",
    "    similar_movies = [movie for movie in similar_movies if movie[0] != movie_id]\n",
    "    \n",
    "    return similar_movies\n",
    "\n",
    "# similiar film to movieId 1\n",
    "movie_recommendation_min_hash(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the similiarity function (Genre-hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class OptimizedMovieLSH:\n",
    "    def __init__(self, num_hash_functions=10, num_bands=5):\n",
    "        self.num_hash_functions = num_hash_functions\n",
    "        self.num_bands = num_bands\n",
    "        self.hash_functions = None\n",
    "        self.precomputed_hashes = None\n",
    "        self.movie_ids = None\n",
    "        self.hash_tables = None\n",
    "        \n",
    "    def generate_hash_functions(self, num_genres):\n",
    "        \"\"\"Generate bit sampling positions for each band.\"\"\"\n",
    "        # Create a (num_bands, num_hash_functions) array of bit positions\n",
    "        self.hash_functions = np.array([\n",
    "            np.random.choice(num_genres, size=self.num_hash_functions, replace=True)\n",
    "            for _ in range(self.num_bands)\n",
    "        ])\n",
    "    \n",
    "    def _compute_all_hashes(self, genre_matrix):\n",
    "        \"\"\"\n",
    "        Compute all hashes for all movies at once using vectorized operations.\n",
    "        \n",
    "        Args:\n",
    "            genre_matrix: numpy array of shape (num_movies, num_genres)\n",
    "        Returns:\n",
    "            numpy array of shape (num_bands, num_movies) containing hash values\n",
    "        \"\"\"\n",
    "        num_movies = genre_matrix.shape[0]\n",
    "        # Preallocate array for hash values\n",
    "        hashes = np.zeros((self.num_bands, num_movies), dtype=np.int32)\n",
    "        \n",
    "        # For each band, compute hashes for all movies at once\n",
    "        for band in range(self.num_bands):\n",
    "            # Select bits for this band (vectorized operation)\n",
    "            selected_bits = genre_matrix[:, self.hash_functions[band]]\n",
    "            \n",
    "            # Convert bits to integers using binary weights\n",
    "            # This creates a unique hash value from the selected bits\n",
    "            powers_of_two = 2 ** np.arange(self.num_hash_functions)\n",
    "            hashes[band] = selected_bits.dot(powers_of_two)\n",
    "            \n",
    "        return hashes\n",
    "    \n",
    "    def index_movies(self, df, genres_list):\n",
    "        \"\"\"\n",
    "        Index all movies using vectorized operations.\n",
    "        \"\"\"\n",
    "        if self.hash_functions is None:\n",
    "            self.generate_hash_functions(len(genres_list))\n",
    "        \n",
    "        # Convert DataFrame to numpy array for faster operations\n",
    "        genre_matrix = df[genres_list].values\n",
    "        self.movie_ids = np.array(df.index)\n",
    "        \n",
    "        # Compute all hashes at once\n",
    "        self.precomputed_hashes = self._compute_all_hashes(genre_matrix)\n",
    "        \n",
    "        # Create hash tables using numpy operations\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.num_bands)]\n",
    "        \n",
    "        # Vectorized hash table construction\n",
    "        for band in range(self.num_bands):\n",
    "            unique_hashes, inverse_indices = np.unique(self.precomputed_hashes[band], \n",
    "                                                     return_inverse=True)\n",
    "            # Create hash tables using numpy operations\n",
    "            for i, hash_val in enumerate(unique_hashes):\n",
    "                matching_movies = self.movie_ids[inverse_indices == i]\n",
    "                self.hash_tables[band][hash_val] = matching_movies.tolist()\n",
    "    \n",
    "    def query(self, query_vector, threshold=10):\n",
    "        \"\"\"\n",
    "        Find similar movies using vectorized operations.\n",
    "        \n",
    "        Args:\n",
    "            query_vector: Binary vector of genre features\n",
    "            threshold: Minimum number of matching bands\n",
    "        \"\"\"\n",
    "        # Compute query hashes using the same method\n",
    "        query_hashes = np.zeros(self.num_bands, dtype=np.int32)\n",
    "        \n",
    "        for band in range(self.num_bands):\n",
    "            selected_bits = query_vector[self.hash_functions[band]]\n",
    "            powers_of_two = 2 ** np.arange(self.num_hash_functions)\n",
    "            query_hashes[band] = selected_bits.dot(powers_of_two)\n",
    "        \n",
    "        # Count matches for each movie using vectorized operations\n",
    "        candidate_counts = defaultdict(int)\n",
    "        \n",
    "        # Use numpy operations to find matching movies\n",
    "        for band, query_hash in enumerate(query_hashes):\n",
    "            matching_movies = self.hash_tables[band].get(query_hash, [])\n",
    "            for movie_id in matching_movies:\n",
    "                candidate_counts[movie_id] += 1\n",
    "        \n",
    "        return {movie_id for movie_id, count in candidate_counts.items() \n",
    "                if count >= threshold}\n",
    "\n",
    "    def save_state(self, filename):\n",
    "        \"\"\"Save the LSH state efficiently using numpy.\"\"\"\n",
    "        np.savez_compressed(\n",
    "            filename,\n",
    "            hash_functions=self.hash_functions,\n",
    "            precomputed_hashes=self.precomputed_hashes,\n",
    "            movie_ids=self.movie_ids\n",
    "        )\n",
    "    \n",
    "    def load_state(self, filename):\n",
    "        \"\"\"Load the LSH state and rebuild hash tables efficiently.\"\"\"\n",
    "        data = np.load(filename)\n",
    "        self.hash_functions = data['hash_functions']\n",
    "        self.precomputed_hashes = data['precomputed_hashes']\n",
    "        self.movie_ids = data['movie_ids']\n",
    "        \n",
    "        # Rebuild hash tables efficiently\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.num_bands)]\n",
    "        for band in range(self.num_bands):\n",
    "            unique_hashes, inverse_indices = np.unique(self.precomputed_hashes[band], \n",
    "                                                     return_inverse=True)\n",
    "            for i, hash_val in enumerate(unique_hashes):\n",
    "                matching_movies = self.movie_ids[inverse_indices == i]\n",
    "                self.hash_tables[band][hash_val] = matching_movies.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_genres = pd.read_csv('../data/df_genres.csv')\n",
    "\n",
    "genres_list = ['(no genres listed)',\n",
    " 'Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Children',\n",
    " 'Comedy',\n",
    " 'Crime',\n",
    " 'Documentary',\n",
    " 'Drama',\n",
    " 'Fantasy',\n",
    " 'Film-Noir',\n",
    " 'Horror',\n",
    " 'IMAX',\n",
    " 'Musical',\n",
    " 'Mystery',\n",
    " 'Romance',\n",
    " 'Sci-Fi',\n",
    " 'Thriller',\n",
    " 'War',\n",
    " 'Western']\n",
    "\n",
    "# Initialize and index\n",
    "lsh_optim = OptimizedMovieLSH(num_hash_functions=128, num_bands=128)\n",
    "lsh_optim.index_movies(df_genres, genres_list)\n",
    "\n",
    "# Save state efficiently\n",
    "lsh_optim.save_state('../data/'+'movie_lsh_optimized.npz')\n",
    "\n",
    "def batch_find_similar_movies(lsh, df, genres_list, query_movie_ids, \n",
    "                            threshold=2, similarity_threshold=0.3, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Find similar movies for multiple queries efficiently.\n",
    "    \n",
    "    Args:\n",
    "        lsh: OptimizedMovieLSH instance\n",
    "        df: DataFrame with genre data\n",
    "        query_movie_ids: List of movie IDs to find similar movies for\n",
    "        batch_size: Number of queries to process at once\n",
    "    \"\"\"\n",
    "    genre_matrix = df[genres_list].values\n",
    "    results = {}\n",
    "    \n",
    "    # Process queries in batches\n",
    "    for i in range(0, len(query_movie_ids), batch_size):\n",
    "        batch_ids = query_movie_ids[i:i + batch_size]\n",
    "        batch_vectors = genre_matrix[np.searchsorted(df.index, batch_ids)]\n",
    "        \n",
    "        for idx, query_id in enumerate(batch_ids):\n",
    "            candidates = lsh.query(batch_vectors[idx], threshold)\n",
    "            \n",
    "            # Compute similarities using vectorized operations\n",
    "            if candidates:\n",
    "                candidate_vectors = genre_matrix[np.searchsorted(df.index, list(candidates))]\n",
    "                query_vec = batch_vectors[idx]\n",
    "                \n",
    "                # Vectorized Jaccard similarity computation\n",
    "                intersection = (candidate_vectors & query_vec).sum(axis=1)\n",
    "                union = (candidate_vectors | query_vec).sum(axis=1)\n",
    "                similarities = intersection / np.maximum(union, 1)\n",
    "                \n",
    "                # Filter and sort results\n",
    "                mask = similarities >= similarity_threshold\n",
    "                similar_movies = list(zip(np.array(list(candidates))[mask], \n",
    "                                       similarities[mask]))\n",
    "                results[query_id] = sorted(similar_movies, key=lambda x: x[1], \n",
    "                                         reverse=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def movie_recommendation_genres(movie_id):\n",
    "    result_dict = batch_find_similar_movies(query_movie_ids=[movie_id], lsh=lsh_optim, df=df_genres, genres_list=genres_list)\n",
    "    return result_dict[movie_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend using bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(133065, 0.999951774691358), (7930, 0.9999397183641975), (52375, 0.9999397183641975), (141381, 0.9999397183641975), (202263, 0.9999397183641975)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jaccard as jacc_score\n",
    "\n",
    "# Load the data\n",
    "df_bert = pd.read_csv('./../data/df_clusters.csv')\n",
    "\n",
    "def movie_recommendation_bert(movie_id):\n",
    "    \"\"\"\n",
    "    This function takes a movieId and returns a list of recommended movies\n",
    "    based on Jaccard similarity of movies in the same cluster.\n",
    "    \"\"\"\n",
    "    # Get the cluster label for the given movie ID\n",
    "    movie_cluster = df_bert[df_bert['movieId'] == movie_id]\n",
    "\n",
    "    if movie_cluster.empty:\n",
    "        raise ValueError(f\"Movie ID {movie_id} not found in the dataset holding decriptions.\")\n",
    "        \n",
    "    movie_cluster = movie_cluster['cluster_label'].item()\n",
    "    # Load embeddings for the cluster\n",
    "    embeddings = np.load(f'/work3/s204161/data/clustered_embeddings/{movie_cluster}.npy')\n",
    "    \n",
    "    # Reshape embeddings to flatten the last two dimensions\n",
    "    embeddings = embeddings.reshape(embeddings.shape[0], -1)  # Shape becomes (N, 106*768)\n",
    "    \n",
    "    # Filter movies in the same cluster and get their DataFrame indices\n",
    "    cluster_movies = df_bert[df_bert['cluster_label'] == movie_cluster]['movieId'].tolist()\n",
    "    \n",
    "    # Map DataFrame indices to embedding indices\n",
    "    movie_id_to_embedding_index = {idx: i for i, idx in enumerate(cluster_movies)}\n",
    "    \n",
    "    # Check if movie_id exists in the mapping\n",
    "    if movie_id not in movie_id_to_embedding_index:\n",
    "        raise ValueError(f\"Movie ID {movie_id} is not in the cluster {movie_cluster}.\")\n",
    "    \n",
    "    movie_embedding_index = movie_id_to_embedding_index[movie_id]\n",
    "\n",
    "    # Compute Jaccard similarity for the movies in the cluster\n",
    "    similar_movies = []\n",
    "    for idx in cluster_movies:\n",
    "        embedding_idx = movie_id_to_embedding_index[idx]\n",
    "        if embedding_idx != movie_embedding_index:  # Skip the movie itself\n",
    "            similarity = jacc_score(embeddings[movie_embedding_index], embeddings[embedding_idx])\n",
    "            similar_movies.append((idx, similarity))\n",
    "    \n",
    "    # Sort movies by similarity score in descending order \n",
    "    similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return similar_movies\n",
    "\n",
    "# Similar movies to movieId 1\n",
    "recommendations = movie_recommendation_bert(1)[:5]\n",
    "print(recommendations) # jaccard is for movies in cluster very close to 1.0 or just 1.0 for the bert embeddings...\n",
    "df_bert[df_bert['movieId'] == 1].description.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Hell to Victory (1979)\n",
      "In 1939, at a Paris café, six friends of various nationalities vow to meet again at the same spot after the end of WW2.\n",
      "People Under the Stairs, The (1991)\n",
      "Two adults and a juvenile break into a house occupied by a brother and sister and their stolen children. There, they must fight for their lives.\n",
      "Hoax, The (2007)\n",
      "In what would cause a fantastic media frenzy, Clifford Irving sells his bogus biography of Howard Hughes to a premiere publishing house in the early 1970s.\n",
      "One Man Force (1989)\n",
      "In this action packed film, an L. A. cop speeds off to get revenge upon the dirty drug-dealing dogs who killed his partner.\n",
      "In the Year 2889 (1967)\n",
      "In a post nuclear Earth, survivors are stuck in a valley and have to protect themselves from mutant human beings, and each other in some cases.\n"
     ]
    }
   ],
   "source": [
    "#top 10 most similair movies to toy story using BERT embeddings\n",
    "for movieid in recommendations[:10]:\n",
    "    print(df_genres[df_genres['movieId'] == movieid[0]].title.values[0])\n",
    "    print(df_genres[df_genres['movieId'] == movieid[0]].description.values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The global function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get movie_recommendations for all movies that the user has rated 5\n",
    "def get_movie_recommendations(userId, recommendation_function):\n",
    "    \"\"\"\n",
    "    Get movie recommendations for a user based on the movies they have rated 5\n",
    "    userId: int\n",
    "    recommendation_function: function that takes a movieId and returns a list of recommended movies. Output is [(movieId, jaccard_score), ...]\n",
    "\n",
    "    Returns: list of recommended movies [(movieId, jaccard_score), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    movie_recommendations = []\n",
    "    user_ratings = ml_ratings[ml_ratings['userId'] == userId]\n",
    "    user_ratings = user_ratings[user_ratings['rating'] == 5]\n",
    "\n",
    "    for movieId in tqdm(user_ratings['movieId']):\n",
    "        try:\n",
    "            movie_recommendations.append(recommendation_function(movie_id=movieId))\n",
    "        except:\n",
    "            print('No recommendations for movieId:', movieId)\n",
    "\n",
    "    # flatten list and sort by jaccard score\n",
    "    movie_recommendations = [movie for sublist in movie_recommendations for movie in sublist]\n",
    "\n",
    "    movie_recommendations = sorted(movie_recommendations, key=lambda x: x[1], reverse=True)\n",
    "    # remove movies that the user has already rated\n",
    "    movie_recommendations = [movie for movie in movie_recommendations if movie[0] not in user_ratings['movieId']]\n",
    "    \n",
    "    return movie_recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496201fcd15d4b0581c92d5a2a5f5b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for movieId: 318\n",
      "No recommendations for movieId: 3949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc34ee3eff94d5ba1cc5941a0e1817d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for movieId: 58559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc0e58a71784f0697d4d5e7ebcea974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for movieId: 318\n",
      "No recommendations for movieId: 3949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63d24d2873440a38485766d8a70b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for movieId: 356\n",
      "No recommendations for movieId: 3421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af817233e104b77b1fbeefb2f3a3c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1c666b07e6431a86cf8e11e4f4d81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for movieId: 356\n",
      "No recommendations for movieId: 3421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd8f18f07b347da906a13c620b4eb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0dfb4dd5444b95b0a0532745c62c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No recommendations for movieId: 53125\n",
      "No recommendations for movieId: 54001\n",
      "No recommendations for movieId: 56775\n",
      "No recommendations for movieId: 58559\n",
      "No recommendations for movieId: 59315\n",
      "No recommendations for movieId: 59501\n",
      "No recommendations for movieId: 63992\n",
      "No recommendations for movieId: 68319\n",
      "No recommendations for movieId: 69844\n",
      "No recommendations for movieId: 72998\n",
      "No recommendations for movieId: 78772\n",
      "No recommendations for movieId: 79139\n",
      "No recommendations for movieId: 82169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a419917e2314ef68193a7e843ac62eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_ids_list = [304, 6741, 147001]\n",
    "user_recommendations_min_hash = {}\n",
    "user_recommendations_genres = {}\n",
    "user_recommendations_bert = {}\n",
    "for userId in user_ids_list:\n",
    "    user_recommendations_min_hash[userId] = get_movie_recommendations(userId, movie_recommendation_min_hash)[:]\n",
    "    user_recommendations_genres[userId] = get_movie_recommendations(userId, movie_recommendation_genres)[:]\n",
    "    user_recommendations_bert[userId] = get_movie_recommendations(userId, movie_recommendation_bert)[:]\n",
    "\n",
    "\n",
    "# save recommendations\n",
    "with open('../data/recommendations/user_recommendations_min_hash.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_min_hash, f)\n",
    "\n",
    "with open('../data/recommendations/user_recommendations_genres.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_genres, f)\n",
    "\n",
    "with open('../data/recommendations/user_recommendations_bert.pkl', 'wb') as f:\n",
    "    pickle.dump(user_recommendations_bert, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolsk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
