{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/movie_graph.pickle', 'rb') as f:\n",
    "#     G = pickle.load(f)\n",
    "\n",
    "# Create a new graph\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "edges = [\n",
    "    (1, 4, 10),\n",
    "    (1, 2, 6),\n",
    "    (1, 3, 5),\n",
    "    (1, 5, 11),\n",
    "    (2, 3, 15),\n",
    "    (2, 4, 4),\n",
    "    (3, 4, 8),\n",
    "    (3, 5, 9),\n",
    "    (4, 5, 7)\n",
    "]\n",
    "\n",
    "G.add_weighted_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_movies(G: nx.Graph, user_watched_movies: list[int], weighted: bool = True):\n",
    "    \"\"\"\n",
    "    Predicts movies for a user based on their watched movies and a graph of movie relationships.\n",
    "\n",
    "    Args:\n",
    "        G: Graph representing movie relationships. Each edge can have a weight.\n",
    "        user_watched_movies: List of movies watched by the user.\n",
    "        weighted: Boolean indicating whether predictions should consider edge weights.\n",
    "\n",
    "    Returns:\n",
    "        A sorted list of recommended movie IDs based on their predicted relevance.\n",
    "    \"\"\"\n",
    "    # Use a single dictionary for neighbor counts or weights\n",
    "    recommendations = defaultdict(float)\n",
    "\n",
    "    # Iterate over each watched movie and process its neighbors\n",
    "    for movie in user_watched_movies:\n",
    "        for neighbor, edge_attrs in G.adj[movie].items():\n",
    "            if neighbor not in user_watched_movies:\n",
    "                weight = edge_attrs.get(\"weight\", 1)\n",
    "                recommendations[neighbor] += weight if weighted else 1\n",
    "\n",
    "    # Convert recommendations to a DataFrame and sort by the chosen metric\n",
    "    metric = \"weight\" if weighted else \"count\"\n",
    "    predictions = (\n",
    "        pd.DataFrame.from_dict(recommendations, orient=\"index\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"movieId\", 0: metric})\n",
    "        .sort_values(by=metric, ascending=False)\n",
    "    )\n",
    "\n",
    "    return predictions[\"movieId\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ml-32m/ratings.csv\")\n",
    "movie_descs = pd.read_csv(\"data/movies_with_description.csv\")\n",
    "ratings = ratings[ratings[\"movieId\"].isin(movie_descs[\"movieId\"])]\n",
    "ratings = ratings[ratings[\"rating\"] >= 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "14\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "users_to_analyze = [304, 6741, 147001]\n",
    "\n",
    "preds = {u: [] for u in users_to_analyze}\n",
    "preds_weighted = {u: [] for u in users_to_analyze}\n",
    "\n",
    "\n",
    "for user in users_to_analyze:\n",
    "    movies_watched = ratings[ratings[\"userId\"] == user][\"movieId\"].tolist()\n",
    "\n",
    "    preds[user] = predict_movies(G, movies_watched, weighted=True)\n",
    "    preds_weighted[user] = predict_movies(G, movies_watched, weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([159728,  75092, 200188, 181434,  17846,  79939,  13636,  99096,  57110,\n",
       "        41467,\n",
       "       ...\n",
       "       112098, 166589, 171170,  28029,  40618, 171528, 181771,  90671,  93161,\n",
       "        44792],\n",
       "      dtype='int64', name='userId', length=1000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sample 1000 users that have at least 5 ratings\n",
    "users_to_analyze = ratings[\"userId\"].value_counts()[ratings[\"userId\"].value_counts() >= 5].sample(1000).index\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "K = 5\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "for user in users_to_analyze:\n",
    "    movies_watched = ratings[ratings[\"userId\"] == user][\"movieId\"].tolist()\n",
    "    \n",
    "    if len(movies_watched) < 5:\n",
    "        continue\n",
    "    \n",
    "    train_movies, test_movies = train_test_split(movies_watched, test_size=TEST_SIZE, random_state=42)\n",
    "    \n",
    "    predicted_movies = predict_movies(G, train_movies, weighted=True)[:K]\n",
    "    \n",
    "    correct_predictions = any(movie in test_movies for movie in predicted_movies)\n",
    "    \n",
    "    accuracies.append(correct_predictions)\n",
    "\n",
    "accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
