{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1       17     4.0  944249077\n",
       "1       1       25     1.0  944250228\n",
       "2       1       29     2.0  943230976\n",
       "3       1       30     5.0  944249077\n",
       "4       1       32     5.0  943228858"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = cudf.read_csv('data/ml-32m/ratings.csv')\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_descs = cudf.read_csv('data/movies_with_description.csv')\n",
    "\n",
    "# Filter all ratings that not in movie_descs\n",
    "\n",
    "ratings = ratings[ratings['movieId'].isin(movie_descs['movieId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886eeaf3eb2e49ce929fc18a7a2362ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ratings:   0%|          | 0/33491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb9d0e444a6457c9c6abad118b8d572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mlen\u001b[39m(users), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(users)):\n\u001b[0;32m---> 14\u001b[0m         edges[(\u001b[43musers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, users[j]\u001b[38;5;241m.\u001b[39mitem())] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m         edges[(users[j]\u001b[38;5;241m.\u001b[39mitem(), users[i]\u001b[38;5;241m.\u001b[39mitem())] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Create an edgelist from the dataframe\n",
    "edges = defaultdict(lambda: 0)\n",
    "\n",
    "ratings_filtered = ratings.query(\"rating >= 4\")\n",
    "\n",
    "# Group by movieId and create edges\n",
    "for movie_id, group in tqdm(ratings_filtered.groupby('movieId'), desc=\"Processing ratings\", leave=False):\n",
    "    users = group['userId'].values\n",
    "    for i in trange(len(users), leave=False):\n",
    "        for j in range(i + 1, len(users)):\n",
    "            edges[(users[i].item(), users[j].item())] += 1\n",
    "            edges[(users[j].item(), users[i].item())] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33701 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d58256879ec4bdaa53364d8a24c1d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ratings:   0%|          | 0/33491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 195.05 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/protocol/pickle.py:60\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(x, buffer_callback, protocol)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdump_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function process_group at 0x7f6522b4d4e0>: it's not the same object as __main__.process_group",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/protocol/pickle.py:65\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(x, buffer_callback, protocol)\u001b[0m\n\u001b[1;32m     64\u001b[0m buffers\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m---> 65\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m result \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function process_group at 0x7f6522b4d4e0>: it's not the same object as __main__.process_group",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     delayed_results\u001b[38;5;241m.\u001b[39mappend(process_group(movie_id, group))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Compute the results using the Dask client\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Combine the results\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m local_edges \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3681\u001b[0m, in \u001b[0;36mClient.compute\u001b[0;34m(self, collections, sync, optimize_graph, workers, allow_other_workers, resources, retries, priority, fifo_timeout, actors, traverse, **kwargs)\u001b[0m\n\u001b[1;32m   3678\u001b[0m dependencies\u001b[38;5;241m.\u001b[39mupdate(dsk\u001b[38;5;241m.\u001b[39mdependencies)\n\u001b[1;32m   3679\u001b[0m dsk \u001b[38;5;241m=\u001b[39m HighLevelGraph(layers, dependencies)\n\u001b[0;32m-> 3681\u001b[0m futures_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_to_futures\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_other_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_other_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3688\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_priority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfifo_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfifo_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3694\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3695\u001b[0m futures \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/client.py:3355\u001b[0m, in \u001b[0;36mClient._graph_to_futures\u001b[0;34m(self, dsk, keys, span_metadata, workers, allow_other_workers, internal_priority, user_priority, resources, retries, fifo_timeout, actors)\u001b[0m\n\u001b[1;32m   3352\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n\u001b[1;32m   3353\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToPickle\n\u001b[0;32m-> 3355\u001b[0m header, frames \u001b[38;5;241m=\u001b[39m \u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mToPickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3357\u001b[0m pickled_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(nbytes, [header] \u001b[38;5;241m+\u001b[39m frames))\n\u001b[1;32m   3358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pickled_size \u001b[38;5;241m>\u001b[39m parse_bytes(\n\u001b[1;32m   3359\u001b[0m     dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed.admin.large-graph-warning-threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3360\u001b[0m ):\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/protocol/serialize.py:366\u001b[0m, in \u001b[0;36mserialize\u001b[0;34m(x, serializers, on_error, context, iterate_collection)\u001b[0m\n\u001b[1;32m    364\u001b[0m dumps, _, wants_context \u001b[38;5;241m=\u001b[39m families[name]\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     header, frames \u001b[38;5;241m=\u001b[39m \u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m wants_context \u001b[38;5;28;01melse\u001b[39;00m dumps(x)\n\u001b[1;32m    367\u001b[0m     header[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserializer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m header, frames\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/protocol/serialize.py:78\u001b[0m, in \u001b[0;36mpickle_dumps\u001b[0;34m(x, context)\u001b[0m\n\u001b[1;32m     75\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m     76\u001b[0m     writeable\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadonly)\n\u001b[0;32m---> 78\u001b[0m frames[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickle-protocol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m header \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserializer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwriteable\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(writeable),\n\u001b[1;32m     86\u001b[0m }\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m header, frames\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/distributed/protocol/pickle.py:77\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(x, buffer_callback, protocol)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     buffers\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m---> 77\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdump_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to serialize \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1529\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m   1528\u001b[0m     cp \u001b[38;5;241m=\u001b[39m Pickler(file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback)\n\u001b[0;32m-> 1529\u001b[0m     \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1295\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdump(obj)\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(e\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/work3/s204071/ctds_02807/.venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1340\u001b[0m, in \u001b[0;36mPickler.reducer_override\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1329\u001b[0m dispatch \u001b[38;5;241m=\u001b[39m dispatch_table\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;66;03m# Implementation of the reducer_override callback, in order to\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;66;03m# efficiently serialize dynamic functions and classes by subclassing\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;66;03m# the C-implemented `pickle.Pickler`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;66;03m# availability of both notions coincide on CPython's pickle, but it may\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;66;03m# not be the case anymore when pypy implements protocol 5.\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreducer_override\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Type-agnostic reducing callback for function and classes.\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    For performance reasons, subclasses of the C `pickle.Pickler` class\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;124;03m      https://github.com/cloudpipe/cloudpickle/issues/248\u001b[39;00m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1371\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(obj)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from dask.distributed import Client, progress\n",
    "from os import environ\n",
    "\n",
    "cpus = cpu_count() // 2\n",
    "\n",
    "client = Client(f\"{environ[\"HOSTNAME\"]}:88991\", n_workers=cpus, threads_per_worker=1, processes=True, memory_limit='4GB')\n",
    "\n",
    "# Create an edgelist from the dataframe\n",
    "edges = defaultdict(lambda: 0)\n",
    "\n",
    "ratings_filtered = ratings.query(\"rating >= 4\")\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "dask_ratings_filtered = dd.from_pandas(ratings_filtered.to_pandas(), npartitions=8)\n",
    "\n",
    "@delayed\n",
    "def process_group(movie_id, group):\n",
    "    local_edges = defaultdict(lambda: 0)\n",
    "    users = group['userId'].values\n",
    "    for i in range(len(users)):\n",
    "        for j in range(i + 1, len(users)):\n",
    "            local_edges[(users[i].item(), users[j].item())] += 1\n",
    "            local_edges[(users[j].item(), users[i].item())] += 1\n",
    "    return local_edges\n",
    "\n",
    "movie_groups = dask_ratings_filtered.groupby('movieId')\n",
    "\n",
    "# Group by movieId and create edges in parallel\n",
    "delayed_results = []\n",
    "for movieId in tqdm(dask_ratings_filtered['movieId'].unique(), desc=\"Processing ratings\", leave=False):\n",
    "    group = movie_groups.get_group(movieId)\n",
    "    delayed_results.append(process_group(movie_id, group))\n",
    "\n",
    "# Compute the results using the Dask client\n",
    "results = client.compute(delayed_results, sync=True)\n",
    "\n",
    "# Combine the results\n",
    "for local_edges in results:\n",
    "    for key, value in local_edges.items():\n",
    "        edges[key] += value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
