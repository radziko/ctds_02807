{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>114709</td>\n",
       "      <td>A cowboy doll is profoundly threatened and jea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>113497</td>\n",
       "      <td>When two kids find and play a magical board ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>113277</td>\n",
       "      <td>949.0</td>\n",
       "      <td>113277</td>\n",
       "      <td>A group of high-end professional thieves start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children</td>\n",
       "      <td>112302</td>\n",
       "      <td>45325.0</td>\n",
       "      <td>112302</td>\n",
       "      <td>Two best friends witness a murder and embark o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "      <td>114576</td>\n",
       "      <td>9091.0</td>\n",
       "      <td>114576</td>\n",
       "      <td>A former fireman takes on a group of terrorist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                title                                       genres  \\\n",
       "0        1     Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1        2       Jumanji (1995)                   Adventure|Children|Fantasy   \n",
       "2        6          Heat (1995)                        Action|Crime|Thriller   \n",
       "3        8  Tom and Huck (1995)                           Adventure|Children   \n",
       "4        9  Sudden Death (1995)                                       Action   \n",
       "\n",
       "   imdbId   tmdbId      id                                        description  \n",
       "0  114709    862.0  114709  A cowboy doll is profoundly threatened and jea...  \n",
       "1  113497   8844.0  113497  When two kids find and play a magical board ga...  \n",
       "2  113277    949.0  113277  A group of high-end professional thieves start...  \n",
       "3  112302  45325.0  112302  Two best friends witness a murder and embark o...  \n",
       "4  114576   9091.0  114576  A former fireman takes on a group of terrorist...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load movie data\n",
    "movies = pd.read_pickle('data/imdb/ml_movies_description.pkl')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique movie ids:  51860\n"
     ]
    }
   ],
   "source": [
    "# get a list of unique movie ids\n",
    "movie_ids_imdb = movies['movieId'].unique()\n",
    "\n",
    "# print the number of unique movie ids\n",
    "print('Number of unique movie ids: ', len(movie_ids_imdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1       17     4.0  944249077\n",
       "1       1       25     1.0  944250228\n",
       "2       1       29     2.0  943230976\n",
       "3       1       30     5.0  944249077\n",
       "4       1       32     5.0  943228858"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ratings\n",
    "ratings = pd.read_csv('data/ml-32m/ratings.csv')\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user ids:  84432\n"
     ]
    }
   ],
   "source": [
    "# get a list of unique user ids\n",
    "movie_ids_ml = ratings['movieId'].unique()\n",
    "\n",
    "# print the number of unique user ids\n",
    "print('Number of unique user ids: ', len(movie_ids_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common movie ids:  49892\n",
      "Number of ratings:  25723135\n",
      "Number of unique users:  200947\n"
     ]
    }
   ],
   "source": [
    "### DATA PREPROCESSING ###\n",
    "\n",
    "# get the intersection of movie ids\n",
    "movie_ids = np.intersect1d(movie_ids_imdb, movie_ids_ml)\n",
    "print('Number of common movie ids: ', len(movie_ids))\n",
    "\n",
    "# filter the ratings data to contain only the common movie ids\n",
    "ratings = ratings[ratings['movieId'].isin(movie_ids)]\n",
    "\n",
    "# drop timestamp column\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "\n",
    "# print the number of ratings\n",
    "print('Number of ratings: ', len(ratings))\n",
    "\n",
    "# get the number of unique users\n",
    "user_ids = ratings['userId'].unique()\n",
    "\n",
    "# print the number of unique users\n",
    "print('Number of unique users: ', len(user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove alle ratings for user 304, 6741 and 147001 for testing purposes\n",
    "ratings = ratings[~ratings['userId'].isin([304, 6741, 147001])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings 4 or 5:  12781764\n",
      "Number of unique users who liked movies:  200609\n",
      "Number of unique movies that were liked:  33491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "3        1       30     5.0\n",
       "4        1       32     5.0\n",
       "9        1      111     5.0\n",
       "11       1      166     5.0\n",
       "15       1      260     5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CREATE LIKED MOVIES DATAFRAME ###\n",
    "# create a dataframe to only store ratings of 4 or 5\n",
    "liked_movies = ratings[ratings['rating'] >= 4]\n",
    "\n",
    "# print the number of liked movies\n",
    "print('Number of ratings 4 or 5: ', len(liked_movies))\n",
    "\n",
    "# print the number of unique users who liked movies\n",
    "print('Number of unique users who liked movies: ', len(liked_movies['userId'].unique()))\n",
    "\n",
    "# print the number of unique movies that were liked\n",
    "print('Number of unique movies that were liked: ', len(liked_movies['movieId'].unique()))\n",
    "\n",
    "liked_movies.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive approach (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create basket data ###\n",
    "# create a basket data\n",
    "baskets = liked_movies.groupby('userId')['movieId'].apply(list).reset_index(name='basket')\n",
    "items = np.unique(np.concatenate(baskets['basket']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200609"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hashcode\n",
       "1         0\n",
       "2         1\n",
       "6         2\n",
       "8         3\n",
       "9         4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a a DataFrame to hash items to integers\n",
    "#df_item_hash = pd.DataFrame({'item': items, 'hashcode': range(len(items))}).set_index('item')\n",
    "df_item_hash = pd.DataFrame(range(len(items)), index=items, columns=['hashcode'])\n",
    "\n",
    "df_item_hash.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each item and store in an array\n",
    "### SLOW ###\n",
    "#item_count_arr = np.zeros((len(items), 1))\n",
    "#for basket in tqdm(baskets['basket']):\n",
    "#    for item in basket:\n",
    "#        idx = df_item_hash.loc[item, 'hashcode']\n",
    "#        item_count_arr[idx] += 1\n",
    "\n",
    "# Count the occurrences of each item and store in an array\n",
    "item_count_arr = np.zeros((len(items), 1))\n",
    "\n",
    "# Flatten the list of baskets and get the corresponding hashcodes\n",
    "flattened_baskets = np.concatenate(baskets['basket'].values)\n",
    "hashcodes = df_item_hash.loc[flattened_baskets, 'hashcode'].values\n",
    "\n",
    "# Use np.bincount to count occurrences of each hashcode\n",
    "item_count_arr[:len(np.bincount(hashcodes))] = np.bincount(hashcodes).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 14229.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     1,     32,     47,     50,    110,    111,    150,    260,\n",
       "          293,    296,    364,    377,    380,    457,    480,    527,\n",
       "          541,    588,    589,    590,    593,    595,    608,    733,\n",
       "          750,    780,    858,    904,    912,    924,   1036,   1089,\n",
       "         1097,   1136,   1196,   1197,   1198,   1200,   1206,   1208,\n",
       "         1210,   1213,   1214,   1221,   1222,   1240,   1258,   1265,\n",
       "         1270,   1291,   1527,   1580,   1617,   1732,   2028,   2324,\n",
       "         2329,   2571,   2716,   2762,   2997,   3114,   3147,   3578,\n",
       "         3996,   4011,   4226,   4306,   4878,   4886,   4963,   4993,\n",
       "         4995,   5418,   5445,   5618,   5952,   5989,   6016,   6377,\n",
       "         6539,   6874,   7153,   7361,   7438,   8961,  33794,  44191,\n",
       "        48516,  48780,  58559,  59315,  60069,  68157,  68954,  74458,\n",
       "        79132,  91529,  99114, 109487])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find frequent items (items that appear in more than 0.5% of the baskets)\n",
    "freq_items = np.array([df_item_hash[df_item_hash['hashcode'] == x].index[0] for x in tqdm(np.where(item_count_arr > 0.1 * len(baskets))[0])])\n",
    "freq_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS IS SLOW ###\n",
    "\n",
    "### hash the frequent items (starting from 1)\n",
    "#df_freq_item_hash = pd.DataFrame(range(1,len(freq_items)+1), index=freq_items, columns=['hashcode'])\n",
    "\n",
    "# create a matrix to store the pair counts\n",
    "#pair_mat_hashed = np.zeros((len(freq_items)+1, len(freq_items)+1))\n",
    "\n",
    "#for b in tqdm(baskets['basket']):\n",
    "#    cand_list = [item for item in b if item in freq_items]\n",
    "#    if len(cand_list)<2:\n",
    "#        continue\n",
    "#    for idx, item1 in enumerate(cand_list):\n",
    "#        for item2 in cand_list[idx+1:]:\n",
    "#            i = df_freq_item_hash.loc[item1,'hashcode'] \n",
    "#            j = df_freq_item_hash.loc[item2,'hashcode'] \n",
    "#            pair_mat_hashed[max(i,j),min(i,j)]+=1\n",
    "\n",
    "# pair_mat\n",
    "#pair_mat_hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200609/200609 [00:03<00:00, 55619.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "       [    0., 13780.,     0., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [    0.,  6572.,  4285., ...,     0.,     0.,     0.],\n",
       "       [    0.,  6391.,  5096., ..., 10369.,     0.,     0.],\n",
       "       [    0.,  6995.,  5332., ..., 11635., 12167.,     0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix to store the pair counts\n",
    "pair_mat_hashed = np.zeros((len(freq_items)+1, len(freq_items)+1))\n",
    "\n",
    "# Create a dictionary for quick lookup of hashcodes\n",
    "df_freq_item_hash = pd.DataFrame(range(1,len(freq_items)+1), index=freq_items, columns=['hashcode'])\n",
    "\n",
    "hashcode_dict = df_freq_item_hash['hashcode'].to_dict()\n",
    "\n",
    "for b in tqdm(baskets['basket']):\n",
    "    # Filter items in the basket to only those in hashcode_dict\n",
    "    cand_list = [hashcode_dict[item] for item in b if item in hashcode_dict]\n",
    "    if len(cand_list) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Convert cand_list to a numpy array\n",
    "    cand_list = np.array(cand_list)\n",
    "    \n",
    "    # Get unique pairs of indices\n",
    "    i_indices = np.maximum.outer(cand_list, cand_list)\n",
    "    j_indices = np.minimum.outer(cand_list, cand_list)\n",
    "    \n",
    "    # Increment only unique pairs (i, j) where i > j\n",
    "    unique_pairs = np.triu_indices_from(i_indices, k=1)\n",
    "    pair_mat_hashed[i_indices[unique_pairs], j_indices[unique_pairs]] += 1\n",
    "\n",
    "# Display the pair matrix\n",
    "pair_mat_hashed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent pairs:  216\n"
     ]
    }
   ],
   "source": [
    "# Get frequent pairs (pairs that appear in more than 0.05% of the baskets - support = 0.0005)\n",
    "# Extract frequent pairs that exceed support s2 (assume s2 = 0.02), and hash back.\n",
    "\n",
    "# Find indices where pair counts exceed the threshold\n",
    "pair_indices = np.where(pair_mat_hashed > 0.1 * len(baskets))\n",
    "\n",
    "# Extract frequent pairs and hash back\n",
    "freq_pairs = np.array([\n",
    "    [df_freq_item_hash.index[x-1], df_freq_item_hash.index[y-1]]\n",
    "    for x, y in zip(pair_indices[0], pair_indices[1])\n",
    "])\n",
    "\n",
    "print('Number of frequent pairs: ', len(freq_pairs))\n",
    "\n",
    "# make this into a list of tuples\n",
    "freq_pairs = [tuple(x) for x in freq_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the support of each frequent pair\n",
    "pair_support = pair_mat_hashed[pair_indices] / len(baskets)\n",
    "\n",
    "# also calculate the confidence of each frequent pair (confidence = support(pair) / support(item1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135672</td>\n",
       "      <td>(50, 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103016</td>\n",
       "      <td>(110, 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104726</td>\n",
       "      <td>(50, 110)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120329</td>\n",
       "      <td>(1, 260)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101685</td>\n",
       "      <td>(260, 47)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0  0.135672   (50, 47)\n",
       "1  0.103016  (110, 47)\n",
       "2  0.104726  (50, 110)\n",
       "3  0.120329   (1, 260)\n",
       "4  0.101685  (260, 47)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame to store the frequent pairs and their support\n",
    "df_freq_pairs = pd.DataFrame(freq_pairs, columns=['item1', 'item2'])\n",
    "df_freq_pairs['support'] = pair_support.flatten()\n",
    "\n",
    "# make one column called itemsets that contains the frequent pairs as tuples (frozen sets)\n",
    "df_freq_pairs['itemsets'] = df_freq_pairs[['item1', 'item2']].apply(lambda x: frozenset(x), axis=1)\n",
    "\n",
    "# drop the item1 and item2 columns\n",
    "df_freq_pairs = df_freq_pairs.drop(['item1', 'item2'], axis=1)\n",
    "\n",
    "df_freq_pairs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule Mining w. A-priori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSOCIATION RULE MINING WITH APRIORI ###\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = liked_movies\n",
    "transactions = df_subset.groupby('userId')['movieId'].apply(list).values\n",
    "\n",
    "# Use TransactionEncoder to convert the data into a binary matrix\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "binary_df = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Frequent Itemsets\n",
    "\n",
    "### Using Minimum Support Threshold of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets (with more than one element):\n",
      "     support      itemsets\n",
      "0   0.226894           (1)\n",
      "1   0.237975          (47)\n",
      "2   0.276025          (50)\n",
      "3   0.239411         (110)\n",
      "4   0.318321         (260)\n",
      "5   0.385706         (296)\n",
      "6   0.208525         (480)\n",
      "7   0.295635         (527)\n",
      "8   0.235533         (589)\n",
      "9   0.351694         (593)\n",
      "10  0.220598         (608)\n",
      "11  0.272894         (858)\n",
      "12  0.275681        (1196)\n",
      "13  0.253284        (1198)\n",
      "14  0.238334        (1210)\n",
      "15  0.211356        (1270)\n",
      "16  0.211561        (2028)\n",
      "17  0.358648        (2571)\n",
      "18  0.205679        (4226)\n",
      "19  0.272126        (4993)\n",
      "20  0.248533        (5952)\n",
      "21  0.250183        (7153)\n",
      "22  0.230089       (58559)\n",
      "23  0.220204       (79132)\n",
      "24  0.229815   (1196, 260)\n",
      "25  0.200156   (1210, 260)\n",
      "26  0.222119    (296, 593)\n",
      "27  0.219970  (5952, 4993)\n",
      "28  0.218071  (4993, 7153)\n",
      "29  0.212493  (5952, 7153)\n"
     ]
    }
   ],
   "source": [
    "# frequent itemsets\n",
    "min_support = 0.2\n",
    "frequent_itemsets_2 = apriori(binary_df, min_support=min_support, use_colnames=True)\n",
    "print(\"Frequent Itemsets (with more than one element):\")\n",
    "print(frequent_itemsets_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets_2['length'] = frequent_itemsets_2['itemsets'].apply(lambda x: len(x))\n",
    "len(frequent_itemsets_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules \n",
    "rules_apriori_2 = association_rules(frequent_itemsets_2, metric=\"confidence\", min_threshold=0.5, num_itemsets=len(transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1196)</td>\n",
       "      <td>(260)</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.229815</td>\n",
       "      <td>0.833629</td>\n",
       "      <td>2.618833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>4.097336</td>\n",
       "      <td>0.853422</td>\n",
       "      <td>0.631038</td>\n",
       "      <td>0.755939</td>\n",
       "      <td>0.777795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(260)</td>\n",
       "      <td>(1196)</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.229815</td>\n",
       "      <td>0.721961</td>\n",
       "      <td>2.618833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>2.605102</td>\n",
       "      <td>0.906805</td>\n",
       "      <td>0.631038</td>\n",
       "      <td>0.616138</td>\n",
       "      <td>0.777795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1210)</td>\n",
       "      <td>(260)</td>\n",
       "      <td>0.238334</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.200156</td>\n",
       "      <td>0.839810</td>\n",
       "      <td>2.638251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124289</td>\n",
       "      <td>4.255445</td>\n",
       "      <td>0.815267</td>\n",
       "      <td>0.561447</td>\n",
       "      <td>0.765007</td>\n",
       "      <td>0.734298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(260)</td>\n",
       "      <td>(1210)</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.238334</td>\n",
       "      <td>0.200156</td>\n",
       "      <td>0.628786</td>\n",
       "      <td>2.638251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124289</td>\n",
       "      <td>2.051822</td>\n",
       "      <td>0.910928</td>\n",
       "      <td>0.561447</td>\n",
       "      <td>0.512628</td>\n",
       "      <td>0.734298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(296)</td>\n",
       "      <td>(593)</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>0.222119</td>\n",
       "      <td>0.575876</td>\n",
       "      <td>1.637435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086468</td>\n",
       "      <td>1.528577</td>\n",
       "      <td>0.633717</td>\n",
       "      <td>0.431063</td>\n",
       "      <td>0.345797</td>\n",
       "      <td>0.603722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(593)</td>\n",
       "      <td>(296)</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.222119</td>\n",
       "      <td>0.631568</td>\n",
       "      <td>1.637435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086468</td>\n",
       "      <td>1.667320</td>\n",
       "      <td>0.600471</td>\n",
       "      <td>0.431063</td>\n",
       "      <td>0.400235</td>\n",
       "      <td>0.603722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(5952)</td>\n",
       "      <td>(4993)</td>\n",
       "      <td>0.248533</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.219970</td>\n",
       "      <td>0.885074</td>\n",
       "      <td>3.252436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152338</td>\n",
       "      <td>6.333390</td>\n",
       "      <td>0.921582</td>\n",
       "      <td>0.731553</td>\n",
       "      <td>0.842107</td>\n",
       "      <td>0.846706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(4993)</td>\n",
       "      <td>(5952)</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.248533</td>\n",
       "      <td>0.219970</td>\n",
       "      <td>0.808338</td>\n",
       "      <td>3.252436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152338</td>\n",
       "      <td>3.920799</td>\n",
       "      <td>0.951454</td>\n",
       "      <td>0.731553</td>\n",
       "      <td>0.744950</td>\n",
       "      <td>0.846706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(4993)</td>\n",
       "      <td>(7153)</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.218071</td>\n",
       "      <td>0.801359</td>\n",
       "      <td>3.203090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.149990</td>\n",
       "      <td>3.774737</td>\n",
       "      <td>0.944946</td>\n",
       "      <td>0.716776</td>\n",
       "      <td>0.735081</td>\n",
       "      <td>0.836502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(7153)</td>\n",
       "      <td>(4993)</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.218071</td>\n",
       "      <td>0.871645</td>\n",
       "      <td>3.203090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.149990</td>\n",
       "      <td>5.670793</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.716776</td>\n",
       "      <td>0.823658</td>\n",
       "      <td>0.836502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(5952)</td>\n",
       "      <td>(7153)</td>\n",
       "      <td>0.248533</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.212493</td>\n",
       "      <td>0.854988</td>\n",
       "      <td>3.417448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150314</td>\n",
       "      <td>5.170728</td>\n",
       "      <td>0.941338</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.852169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(7153)</td>\n",
       "      <td>(5952)</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.248533</td>\n",
       "      <td>0.212493</td>\n",
       "      <td>0.849349</td>\n",
       "      <td>3.417448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150314</td>\n",
       "      <td>4.988145</td>\n",
       "      <td>0.943409</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>0.799525</td>\n",
       "      <td>0.852169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0       (1196)       (260)            0.275681            0.318321  0.229815   \n",
       "1        (260)      (1196)            0.318321            0.275681  0.229815   \n",
       "2       (1210)       (260)            0.238334            0.318321  0.200156   \n",
       "3        (260)      (1210)            0.318321            0.238334  0.200156   \n",
       "4        (296)       (593)            0.385706            0.351694  0.222119   \n",
       "5        (593)       (296)            0.351694            0.385706  0.222119   \n",
       "6       (5952)      (4993)            0.248533            0.272126  0.219970   \n",
       "7       (4993)      (5952)            0.272126            0.248533  0.219970   \n",
       "8       (4993)      (7153)            0.272126            0.250183  0.218071   \n",
       "9       (7153)      (4993)            0.250183            0.272126  0.218071   \n",
       "10      (5952)      (7153)            0.248533            0.250183  0.212493   \n",
       "11      (7153)      (5952)            0.250183            0.248533  0.212493   \n",
       "\n",
       "    confidence      lift  representativity  leverage  conviction  \\\n",
       "0     0.833629  2.618833               1.0  0.142060    4.097336   \n",
       "1     0.721961  2.618833               1.0  0.142060    2.605102   \n",
       "2     0.839810  2.638251               1.0  0.124289    4.255445   \n",
       "3     0.628786  2.638251               1.0  0.124289    2.051822   \n",
       "4     0.575876  1.637435               1.0  0.086468    1.528577   \n",
       "5     0.631568  1.637435               1.0  0.086468    1.667320   \n",
       "6     0.885074  3.252436               1.0  0.152338    6.333390   \n",
       "7     0.808338  3.252436               1.0  0.152338    3.920799   \n",
       "8     0.801359  3.203090               1.0  0.149990    3.774737   \n",
       "9     0.871645  3.203090               1.0  0.149990    5.670793   \n",
       "10    0.854988  3.417448               1.0  0.150314    5.170728   \n",
       "11    0.849349  3.417448               1.0  0.150314    4.988145   \n",
       "\n",
       "    zhangs_metric   jaccard  certainty  kulczynski  \n",
       "0        0.853422  0.631038   0.755939    0.777795  \n",
       "1        0.906805  0.631038   0.616138    0.777795  \n",
       "2        0.815267  0.561447   0.765007    0.734298  \n",
       "3        0.910928  0.561447   0.512628    0.734298  \n",
       "4        0.633717  0.431063   0.345797    0.603722  \n",
       "5        0.600471  0.431063   0.400235    0.603722  \n",
       "6        0.921582  0.731553   0.842107    0.846706  \n",
       "7        0.951454  0.731553   0.744950    0.846706  \n",
       "8        0.944946  0.716776   0.735081    0.836502  \n",
       "9        0.917293  0.716776   0.823658    0.836502  \n",
       "10       0.941338  0.742402   0.806604    0.852169  \n",
       "11       0.943409  0.742402   0.799525    0.852169  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_apriori_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 260  296  593 1196 1210 4993 5952 7153]\n",
      "      movieId                                              title\n",
      "163       260          Star Wars: Episode IV - A New Hope (1977)\n",
      "182       296                                Pulp Fiction (1994)\n",
      "373       593                   Silence of the Lambs, The (1991)\n",
      "743      1196  Star Wars: Episode V - The Empire Strikes Back...\n",
      "755      1210  Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "3366     4993  Lord of the Rings: The Fellowship of the Ring,...\n",
      "4031     5952      Lord of the Rings: The Two Towers, The (2002)\n",
      "4831     7153  Lord of the Rings: The Return of the King, The...\n"
     ]
    }
   ],
   "source": [
    "# find all unique movie ids in antecedents and consequents\n",
    "unique_ante = np.unique(np.concatenate(rules_apriori_2['antecedents'].apply(list)))\n",
    "unique_cons = np.unique(np.concatenate(rules_apriori_2['consequents'].apply(list)))\n",
    "\n",
    "#print(len(unique_ante), len(unique_cons))\n",
    "\n",
    "# find the union of unique movie ids in antecedents and consequents\n",
    "unique_movies = np.unique(np.concatenate([unique_ante, unique_cons]))\n",
    "\n",
    "# print the unique movie ids and names\n",
    "print(unique_movies)\n",
    "print(movies[movies['movieId'].isin(unique_movies)][['movieId', 'title']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Minimum Support Threshold of 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets (with more than one element):\n",
      "     support            itemsets\n",
      "0   0.226894                 (1)\n",
      "1   0.184767                (32)\n",
      "2   0.237975                (47)\n",
      "3   0.276025                (50)\n",
      "4   0.239411               (110)\n",
      "..       ...                 ...\n",
      "73  0.172988   (1210, 260, 1196)\n",
      "74  0.155427   (1196, 2571, 260)\n",
      "75  0.153612  (5952, 4993, 2571)\n",
      "76  0.152595  (7153, 4993, 2571)\n",
      "77  0.198810  (5952, 4993, 7153)\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# frequent itemsets\n",
    "min_support = 0.15\n",
    "frequent_itemsets_15 = apriori(binary_df, min_support=min_support, use_colnames=True)\n",
    "print(\"Frequent Itemsets (with more than one element):\")\n",
    "print(frequent_itemsets_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets_15['length'] = frequent_itemsets_15['itemsets'].apply(lambda x: len(x))\n",
    "len(frequent_itemsets_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating association rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules \n",
    "rules_apriori_15 = association_rules(frequent_itemsets_15, metric=\"confidence\", min_threshold=0.5, num_itemsets=len(transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(47)</td>\n",
       "      <td>(296)</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.169589</td>\n",
       "      <td>0.712631</td>\n",
       "      <td>1.847604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>2.137650</td>\n",
       "      <td>0.602026</td>\n",
       "      <td>0.373467</td>\n",
       "      <td>0.532197</td>\n",
       "      <td>0.576158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(47)</td>\n",
       "      <td>(593)</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>0.157814</td>\n",
       "      <td>0.663155</td>\n",
       "      <td>1.885601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074120</td>\n",
       "      <td>1.924639</td>\n",
       "      <td>0.616338</td>\n",
       "      <td>0.365434</td>\n",
       "      <td>0.480422</td>\n",
       "      <td>0.555941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(50)</td>\n",
       "      <td>(296)</td>\n",
       "      <td>0.276025</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.188102</td>\n",
       "      <td>0.681469</td>\n",
       "      <td>1.766812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081638</td>\n",
       "      <td>1.928525</td>\n",
       "      <td>0.599480</td>\n",
       "      <td>0.397152</td>\n",
       "      <td>0.481469</td>\n",
       "      <td>0.584576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(50)</td>\n",
       "      <td>(593)</td>\n",
       "      <td>0.276025</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>0.165182</td>\n",
       "      <td>0.598432</td>\n",
       "      <td>1.701571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>1.614438</td>\n",
       "      <td>0.569505</td>\n",
       "      <td>0.357122</td>\n",
       "      <td>0.380589</td>\n",
       "      <td>0.534054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1196)</td>\n",
       "      <td>(260)</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.229815</td>\n",
       "      <td>0.833629</td>\n",
       "      <td>2.618833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>4.097336</td>\n",
       "      <td>0.853422</td>\n",
       "      <td>0.631038</td>\n",
       "      <td>0.755939</td>\n",
       "      <td>0.777795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>(5952, 7153)</td>\n",
       "      <td>(4993)</td>\n",
       "      <td>0.212493</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>3.438129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140985</td>\n",
       "      <td>11.303387</td>\n",
       "      <td>0.900492</td>\n",
       "      <td>0.695601</td>\n",
       "      <td>0.911531</td>\n",
       "      <td>0.833092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>(4993, 7153)</td>\n",
       "      <td>(5952)</td>\n",
       "      <td>0.218071</td>\n",
       "      <td>0.248533</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>0.911674</td>\n",
       "      <td>3.668218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144612</td>\n",
       "      <td>8.507872</td>\n",
       "      <td>0.930248</td>\n",
       "      <td>0.742396</td>\n",
       "      <td>0.882462</td>\n",
       "      <td>0.855803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>(5952)</td>\n",
       "      <td>(4993, 7153)</td>\n",
       "      <td>0.248533</td>\n",
       "      <td>0.218071</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>0.799932</td>\n",
       "      <td>3.668218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144612</td>\n",
       "      <td>3.908313</td>\n",
       "      <td>0.967958</td>\n",
       "      <td>0.742396</td>\n",
       "      <td>0.744135</td>\n",
       "      <td>0.855803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>(4993)</td>\n",
       "      <td>(5952, 7153)</td>\n",
       "      <td>0.272126</td>\n",
       "      <td>0.212493</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>0.730578</td>\n",
       "      <td>3.438129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140985</td>\n",
       "      <td>2.922953</td>\n",
       "      <td>0.974268</td>\n",
       "      <td>0.695601</td>\n",
       "      <td>0.657880</td>\n",
       "      <td>0.833092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>(7153)</td>\n",
       "      <td>(5952, 4993)</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.219970</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>0.794656</td>\n",
       "      <td>3.612563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143777</td>\n",
       "      <td>3.798653</td>\n",
       "      <td>0.964487</td>\n",
       "      <td>0.732685</td>\n",
       "      <td>0.736749</td>\n",
       "      <td>0.849229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     antecedents   consequents  antecedent support  consequent support  \\\n",
       "0           (47)         (296)            0.237975            0.385706   \n",
       "1           (47)         (593)            0.237975            0.351694   \n",
       "2           (50)         (296)            0.276025            0.385706   \n",
       "3           (50)         (593)            0.276025            0.351694   \n",
       "4         (1196)         (260)            0.275681            0.318321   \n",
       "..           ...           ...                 ...                 ...   \n",
       "63  (5952, 7153)        (4993)            0.212493            0.272126   \n",
       "64  (4993, 7153)        (5952)            0.218071            0.248533   \n",
       "65        (5952)  (4993, 7153)            0.248533            0.218071   \n",
       "66        (4993)  (5952, 7153)            0.272126            0.212493   \n",
       "67        (7153)  (5952, 4993)            0.250183            0.219970   \n",
       "\n",
       "     support  confidence      lift  representativity  leverage  conviction  \\\n",
       "0   0.169589    0.712631  1.847604               1.0  0.077800    2.137650   \n",
       "1   0.157814    0.663155  1.885601               1.0  0.074120    1.924639   \n",
       "2   0.188102    0.681469  1.766812               1.0  0.081638    1.928525   \n",
       "3   0.165182    0.598432  1.701571               1.0  0.068106    1.614438   \n",
       "4   0.229815    0.833629  2.618833               1.0  0.142060    4.097336   \n",
       "..       ...         ...       ...               ...       ...         ...   \n",
       "63  0.198810    0.935606  3.438129               1.0  0.140985   11.303387   \n",
       "64  0.198810    0.911674  3.668218               1.0  0.144612    8.507872   \n",
       "65  0.198810    0.799932  3.668218               1.0  0.144612    3.908313   \n",
       "66  0.198810    0.730578  3.438129               1.0  0.140985    2.922953   \n",
       "67  0.198810    0.794656  3.612563               1.0  0.143777    3.798653   \n",
       "\n",
       "    zhangs_metric   jaccard  certainty  kulczynski  \n",
       "0        0.602026  0.373467   0.532197    0.576158  \n",
       "1        0.616338  0.365434   0.480422    0.555941  \n",
       "2        0.599480  0.397152   0.481469    0.584576  \n",
       "3        0.569505  0.357122   0.380589    0.534054  \n",
       "4        0.853422  0.631038   0.755939    0.777795  \n",
       "..            ...       ...        ...         ...  \n",
       "63       0.900492  0.695601   0.911531    0.833092  \n",
       "64       0.930248  0.742396   0.882462    0.855803  \n",
       "65       0.967958  0.742396   0.744135    0.855803  \n",
       "66       0.974268  0.695601   0.657880    0.833092  \n",
       "67       0.964487  0.732685   0.736749    0.849229  \n",
       "\n",
       "[68 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_apriori_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  47   50  260  296  527  593  608  858 1196 1198 1210 1221 2571 4993\n",
      " 5952 7153] 16\n",
      "      movieId                                              title\n",
      "31         47                        Seven (a.k.a. Se7en) (1995)\n",
      "33         50                         Usual Suspects, The (1995)\n",
      "163       260          Star Wars: Episode IV - A New Hope (1977)\n",
      "182       296                                Pulp Fiction (1994)\n",
      "334       527                            Schindler's List (1993)\n",
      "373       593                   Silence of the Lambs, The (1991)\n",
      "382       608                                       Fargo (1996)\n",
      "528       858                              Godfather, The (1972)\n",
      "743      1196  Star Wars: Episode V - The Empire Strikes Back...\n",
      "745      1198  Raiders of the Lost Ark (Indiana Jones and the...\n",
      "755      1210  Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "766      1221                     Godfather: Part II, The (1974)\n",
      "1656     2571                                 Matrix, The (1999)\n",
      "3366     4993  Lord of the Rings: The Fellowship of the Ring,...\n",
      "4031     5952      Lord of the Rings: The Two Towers, The (2002)\n",
      "4831     7153  Lord of the Rings: The Return of the King, The...\n"
     ]
    }
   ],
   "source": [
    "# find all unique movie ids in antecedents and consequents\n",
    "unique_ante = np.unique(np.concatenate(rules_apriori_15['antecedents'].apply(list)))\n",
    "unique_cons = np.unique(np.concatenate(rules_apriori_15['consequents'].apply(list)))\n",
    "\n",
    "#print(len(unique_ante), len(unique_cons))\n",
    "\n",
    "# find the union of unique movie ids in antecedents and consequents\n",
    "unique_movies = np.unique(np.concatenate([unique_ante, unique_cons]))\n",
    "\n",
    "# print the unique movie ids and names\n",
    "print(unique_movies, len(unique_movies))\n",
    "print(movies[movies['movieId'].isin(unique_movies)][['movieId', 'title']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Minimum Support Threshold of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets (with more than one element):\n",
      "      support                   itemsets\n",
      "0    0.226894                        (1)\n",
      "1    0.184767                       (32)\n",
      "2    0.237975                       (47)\n",
      "3    0.276025                       (50)\n",
      "4    0.239411                      (110)\n",
      "..        ...                        ...\n",
      "394  0.114147    (5952, 4993, 260, 7153)\n",
      "395  0.103804    (296, 4993, 5952, 7153)\n",
      "396  0.110778   (5952, 4993, 1196, 7153)\n",
      "397  0.140617   (5952, 7153, 4993, 2571)\n",
      "398  0.105962  (5952, 4993, 7153, 58559)\n",
      "\n",
      "[399 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# frequent itemsets\n",
    "min_support = 0.1\n",
    "frequent_itemsets_1 = apriori(binary_df, min_support=min_support, use_colnames=True)\n",
    "print(\"Frequent Itemsets (with more than one element):\")\n",
    "print(frequent_itemsets_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets_1['length'] = frequent_itemsets_1['itemsets'].apply(lambda x: len(x))\n",
    "len(frequent_itemsets_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules \n",
    "rules_apriori_1 = association_rules(frequent_itemsets_1, metric=\"confidence\", min_threshold=0.5, num_itemsets=len(transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1)</td>\n",
       "      <td>(260)</td>\n",
       "      <td>0.226894</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.120329</td>\n",
       "      <td>0.530329</td>\n",
       "      <td>1.666022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048104</td>\n",
       "      <td>1.451398</td>\n",
       "      <td>0.517093</td>\n",
       "      <td>0.283202</td>\n",
       "      <td>0.311009</td>\n",
       "      <td>0.454170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(32)</td>\n",
       "      <td>(296)</td>\n",
       "      <td>0.184767</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.122726</td>\n",
       "      <td>0.664221</td>\n",
       "      <td>1.722092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051460</td>\n",
       "      <td>1.829458</td>\n",
       "      <td>0.514345</td>\n",
       "      <td>0.274098</td>\n",
       "      <td>0.453390</td>\n",
       "      <td>0.491204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(32)</td>\n",
       "      <td>(593)</td>\n",
       "      <td>0.184767</td>\n",
       "      <td>0.351694</td>\n",
       "      <td>0.104985</td>\n",
       "      <td>0.568203</td>\n",
       "      <td>1.615616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>1.501412</td>\n",
       "      <td>0.467402</td>\n",
       "      <td>0.243317</td>\n",
       "      <td>0.333961</td>\n",
       "      <td>0.433358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(47)</td>\n",
       "      <td>(50)</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>0.276025</td>\n",
       "      <td>0.135672</td>\n",
       "      <td>0.570109</td>\n",
       "      <td>2.065429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>1.684091</td>\n",
       "      <td>0.676932</td>\n",
       "      <td>0.358609</td>\n",
       "      <td>0.406208</td>\n",
       "      <td>0.530815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(47)</td>\n",
       "      <td>(296)</td>\n",
       "      <td>0.237975</td>\n",
       "      <td>0.385706</td>\n",
       "      <td>0.169589</td>\n",
       "      <td>0.712631</td>\n",
       "      <td>1.847604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>2.137650</td>\n",
       "      <td>0.602026</td>\n",
       "      <td>0.373467</td>\n",
       "      <td>0.532197</td>\n",
       "      <td>0.576158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0         (1)       (260)            0.226894            0.318321  0.120329   \n",
       "1        (32)       (296)            0.184767            0.385706  0.122726   \n",
       "2        (32)       (593)            0.184767            0.351694  0.104985   \n",
       "3        (47)        (50)            0.237975            0.276025  0.135672   \n",
       "4        (47)       (296)            0.237975            0.385706  0.169589   \n",
       "\n",
       "   confidence      lift  representativity  leverage  conviction  \\\n",
       "0    0.530329  1.666022               1.0  0.048104    1.451398   \n",
       "1    0.664221  1.722092               1.0  0.051460    1.829458   \n",
       "2    0.568203  1.615616               1.0  0.040004    1.501412   \n",
       "3    0.570109  2.065429               1.0  0.069985    1.684091   \n",
       "4    0.712631  1.847604               1.0  0.077800    2.137650   \n",
       "\n",
       "   zhangs_metric   jaccard  certainty  kulczynski  \n",
       "0       0.517093  0.283202   0.311009    0.454170  \n",
       "1       0.514345  0.274098   0.453390    0.491204  \n",
       "2       0.467402  0.243317   0.333961    0.433358  \n",
       "3       0.676932  0.358609   0.406208    0.530815  \n",
       "4       0.602026  0.373467   0.532197    0.576158  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(rules_apriori_1))\n",
    "\n",
    "rules_apriori_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "       movieId                                              title\n",
      "0            1                                   Toy Story (1995)\n",
      "20          32          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "31          47                        Seven (a.k.a. Se7en) (1995)\n",
      "33          50                         Usual Suspects, The (1995)\n",
      "71         110                                  Braveheart (1995)\n",
      "72         111                                 Taxi Driver (1976)\n",
      "91         150                                   Apollo 13 (1995)\n",
      "163        260          Star Wars: Episode IV - A New Hope (1977)\n",
      "181        293  Léon: The Professional (a.k.a. The Professiona...\n",
      "182        296                                Pulp Fiction (1994)\n",
      "289        457                               Fugitive, The (1993)\n",
      "305        480                               Jurassic Park (1993)\n",
      "334        527                            Schindler's List (1993)\n",
      "343        541                                Blade Runner (1982)\n",
      "369        589                  Terminator 2: Judgment Day (1991)\n",
      "373        593                   Silence of the Lambs, The (1991)\n",
      "382        608                                       Fargo (1996)\n",
      "528        858                              Godfather, The (1972)\n",
      "648       1036                                    Die Hard (1988)\n",
      "681       1089                              Reservoir Dogs (1992)\n",
      "709       1136             Monty Python and the Holy Grail (1975)\n",
      "743       1196  Star Wars: Episode V - The Empire Strikes Back...\n",
      "744       1197                         Princess Bride, The (1987)\n",
      "745       1198  Raiders of the Lost Ark (Indiana Jones and the...\n",
      "747       1200                                      Aliens (1986)\n",
      "755       1210  Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "758       1213                                  Goodfellas (1990)\n",
      "759       1214                                       Alien (1979)\n",
      "766       1221                     Godfather: Part II, The (1974)\n",
      "778       1240                             Terminator, The (1984)\n",
      "802       1270                          Back to the Future (1985)\n",
      "819       1291          Indiana Jones and the Last Crusade (1989)\n",
      "1262      2028                         Saving Private Ryan (1998)\n",
      "1477      2329                          American History X (1998)\n",
      "1656      2571                                 Matrix, The (1999)\n",
      "1783      2762                            Sixth Sense, The (1999)\n",
      "2338      3578                                   Gladiator (2000)\n",
      "2817      4226                                     Memento (2000)\n",
      "2860      4306                                       Shrek (2001)\n",
      "3366      4993  Lord of the Rings: The Fellowship of the Ring,...\n",
      "4031      5952      Lord of the Rings: The Two Towers, The (2002)\n",
      "4649      6874                           Kill Bill: Vol. 1 (2003)\n",
      "4831      7153  Lord of the Rings: The Return of the King, The...\n",
      "4961      7361       Eternal Sunshine of the Spotless Mind (2004)\n",
      "5006      7438                           Kill Bill: Vol. 2 (2004)\n",
      "6858     33794                               Batman Begins (2005)\n",
      "8368     58559                            Dark Knight, The (2008)\n",
      "10097    79132                                   Inception (2010)\n",
      "13780   109487                                Interstellar (2014)\n"
     ]
    }
   ],
   "source": [
    "# find all unique movie ids in antecedents and consequents\n",
    "unique_ante = np.unique(np.concatenate(rules_apriori_1['antecedents'].apply(list)))\n",
    "unique_cons = np.unique(np.concatenate(rules_apriori_1['consequents'].apply(list)))\n",
    "\n",
    "#print(len(unique_ante), len(unique_cons))\n",
    "\n",
    "# find the union of unique movie ids in antecedents and consequents\n",
    "unique_movies = np.unique(np.concatenate([unique_ante, unique_cons]))\n",
    "\n",
    "# print the unique movie ids and names\n",
    "print(len(unique_movies))\n",
    "print(movies[movies['movieId'].isin(unique_movies)][['movieId', 'title']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Minimum Support Threshold of 0.05\n",
    "\n",
    "##### THIS DID NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent itemsets\n",
    "#min_support = 0.05\n",
    "#frequent_itemsets_05 = apriori(binary_df, min_support=min_support, use_colnames=True)\n",
    "#print(\"Frequent Itemsets (with more than one element):\")\n",
    "#print(frequent_itemsets_05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1       17     4.0  944249077\n",
       "1       1       25     1.0  944250228\n",
       "2       1       29     2.0  943230976\n",
       "3       1       30     5.0  944249077\n",
       "4       1       32     5.0  943228858"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ratings\n",
    "ratings = pd.read_csv('data/ml-32m/ratings.csv')\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user ids:  84432\n"
     ]
    }
   ],
   "source": [
    "# get a list of unique user ids\n",
    "movie_ids_ml = ratings['movieId'].unique()\n",
    "\n",
    "# print the number of unique user ids\n",
    "print('Number of unique user ids: ', len(movie_ids_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common movie ids:  49892\n",
      "Number of ratings:  25723135\n",
      "Number of unique users:  200947\n"
     ]
    }
   ],
   "source": [
    "### DATA PREPROCESSING ###\n",
    "\n",
    "# get the intersection of movie ids\n",
    "movie_ids = np.intersect1d(movie_ids_imdb, movie_ids_ml)\n",
    "print('Number of common movie ids: ', len(movie_ids))\n",
    "\n",
    "# filter the ratings data to contain only the common movie ids\n",
    "ratings = ratings[ratings['movieId'].isin(movie_ids)]\n",
    "\n",
    "# drop timestamp column\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "\n",
    "# print the number of ratings\n",
    "print('Number of ratings: ', len(ratings))\n",
    "\n",
    "# get the number of unique users\n",
    "user_ids = ratings['userId'].unique()\n",
    "\n",
    "# print the number of unique users\n",
    "print('Number of unique users: ', len(user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the ratings for user 304, 6741 and 147001\n",
    "test_ratings = ratings[ratings['userId'].isin([304, 6741, 147001])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rules(user_id, rules):\n",
    "    # get the test ratings for the user\n",
    "    test_user = test_ratings[test_ratings['userId'] == user_id]\n",
    "\n",
    "    # get num ratings\n",
    "    num_ratings = len(test_user)\n",
    "    print('Number of ratings for user', user_id, ':', num_ratings)\n",
    "\n",
    "    # using the rules, check if any of the antecedents are in the test ratings\n",
    "    # if they are, check if the consequents are also in the test ratings\n",
    "    # if both are and both are rated higher than 4, increment perfect classification\n",
    "    perfect_recommendation = 0\n",
    "    perfect_rule = []\n",
    "    # if both are rated higher than 3.5, increment good classification\n",
    "    good_recommendation = 0\n",
    "    good_rule = []\n",
    "    # if both are and only one is rated higher than 4, increment bad classification\n",
    "    bad_recommendation = 0\n",
    "    bad_rule = []\n",
    "    \n",
    "    for idx, row in rules.iterrows():\n",
    "        if row['antecedents'].issubset(test_user['movieId']) and row['consequents'].issubset(test_user['movieId']):\n",
    "            if test_user[test_user['movieId'].isin(row['antecedents'])]['rating'].values[0] >= 4 and test_user[test_user['movieId'].isin(row['consequents'])]['rating'].values[0] >= 4:\n",
    "                if [row['consequents'], row['antecedents']] in perfect_rule:\n",
    "                    continue\n",
    "                perfect_recommendation += 1\n",
    "                # append string \"item1 -> item2\" to good_rule \n",
    "                perfect_rule.append([row['antecedents'], row['consequents']])\n",
    "                \n",
    "            elif test_user[test_user['movieId'].isin(row['antecedents'])]['rating'].values[0] >= 3.5 and test_user[test_user['movieId'].isin(row['consequents'])]['rating'].values[0] >= 3.5:\n",
    "                if [row['consequents'], row['antecedents']] in good_rule:\n",
    "                    continue\n",
    "                good_recommendation += 1\n",
    "                # append string \"item1 -> item2\" to good_rule\n",
    "                good_rule.append([row['antecedents'], row['consequents']])\n",
    "            elif test_user[test_user['movieId'].isin(row['antecedents'])]['rating'].values[0] >= 3.5 and test_user[test_user['movieId'].isin(row['consequents'])]['rating'].values[0] < 3.5:\n",
    "                if [row['consequents'], row['antecedents']] in bad_rule:\n",
    "                    continue\n",
    "                bad_recommendation += 1\n",
    "                # append string \"item1 -> item2\" to bad_rule\n",
    "                bad_rule.append([row['antecedents'], row['consequents']])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # it might be the case that rules go both ways, so we need to check for that as well\n",
    "    \n",
    "\n",
    "    return perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Evaluation for Minimum Support = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings for user 304 : 168\n",
      "Perfect recommendation: 1\n",
      "Good recommendation: 0\n",
      "Bad recommendation: 0\n",
      "Number of ratings for user 6741 : 336\n",
      "Perfect recommendation: 5\n",
      "Good recommendation: 0\n",
      "Bad recommendation: 0\n",
      "Number of ratings for user 147001 : 223\n",
      "Perfect recommendation: 3\n",
      "Good recommendation: 1\n",
      "Bad recommendation: 0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the rules for user 304 with a support of 0.2\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(304, rules_apriori_2)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "# evaluate the rules for user 6741 with a support of 0.2\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(6741, rules_apriori_2)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "# evaluate the rules for user 147001 with a support of 0.2\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(147001, rules_apriori_2)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Evaluation for Minimum Support = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings for user 304 : 168\n",
      "Perfect recommendation: 6\n",
      "Good recommendation: 7\n",
      "Bad recommendation: 0\n",
      "Number of ratings for user 6741 : 336\n",
      "Perfect recommendation: 23\n",
      "Good recommendation: 1\n",
      "Bad recommendation: 13\n",
      "Number of ratings for user 147001 : 223\n",
      "Perfect recommendation: 18\n",
      "Good recommendation: 2\n",
      "Bad recommendation: 1\n"
     ]
    }
   ],
   "source": [
    "# evaluate the rules for user 304 with a support of 0.15\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(304, rules_apriori_15)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "\n",
    "# evaluate the rules for user 6741 with a support of 0.15\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(6741, rules_apriori_15)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "\n",
    "# evaluate the rules for user 147001 with a support of 0.15\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(147001, rules_apriori_15)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Evaluation for Minimum Support = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings for user 304 : 168\n",
      "Perfect recommendation: 29\n",
      "Good recommendation: 76\n",
      "Bad recommendation: 0\n",
      "Number of ratings for user 6741 : 336\n",
      "Perfect recommendation: 240\n",
      "Good recommendation: 16\n",
      "Bad recommendation: 55\n",
      "Number of ratings for user 147001 : 223\n",
      "Perfect recommendation: 105\n",
      "Good recommendation: 24\n",
      "Bad recommendation: 5\n"
     ]
    }
   ],
   "source": [
    "# evaluate the rules for user 304 with a support of 0.1\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(304, rules_apriori_1)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "# evaluate the rules for user 6741 with a support of 0.1\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(6741, rules_apriori_1)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "# evaluate the rules for user 147001 with a support of 0.1\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(147001, rules_apriori_1)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further Tests for User 6741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings for user 6741 : 336\n",
      "Perfect recommendation: 240\n",
      "Good recommendation: 16\n",
      "Bad recommendation: 55\n",
      "Antecedent :    movieId                        title\n",
      "31       47  Seven (a.k.a. Se7en) (1995), consequent:       movieId               title\n",
      "1656     2571  Matrix, The (1999)\n",
      "Antecedent :    movieId                       title\n",
      "33       50  Usual Suspects, The (1995), consequent:       movieId               title\n",
      "1656     2571  Matrix, The (1999)\n",
      "Antecedent :     movieId                                      title\n",
      "163      260  Star Wars: Episode IV - A New Hope (1977), consequent:       movieId               title\n",
      "1656     2571  Matrix, The (1999)\n",
      "Antecedent :     movieId                              title\n",
      "369      589  Terminator 2: Judgment Day (1991), consequent:       movieId               title\n",
      "1656     2571  Matrix, The (1999)\n",
      "Antecedent :     movieId                  title\n",
      "528      858  Godfather, The (1972), consequent:       movieId               title\n",
      "1656     2571  Matrix, The (1999)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the rules for user 6741 with a support of 0.1\n",
    "perfect_recommendation, good_recommendation, bad_recommendation, perfect_rule, good_rule, bad_rule = eval_rules(6741, rules_apriori_1)\n",
    "\n",
    "print('Perfect recommendation:', perfect_recommendation)\n",
    "print('Good recommendation:', good_recommendation)\n",
    "print('Bad recommendation:', bad_recommendation)\n",
    "\n",
    "# go through the bad rules and print movie names\n",
    "for rule in bad_rule[:5]:\n",
    "    print(f\"Antecedent :{movies[movies['movieId'].isin(rule[0])][['movieId', 'title']]}, consequent: {movies[movies['movieId'].isin(rule[1])][['movieId', 'title']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
